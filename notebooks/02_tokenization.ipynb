{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DATA_DIR\n",
    "from utils import sample_series, save_df, read_df\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo os dados originais parseados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = read_df('dados_orginais_contribuicoes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>canal</th>\n",
       "      <th>texto</th>\n",
       "      <th>temas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>2802</td>\n",
       "      <td>Participe+</td>\n",
       "      <td>oficinas no Parque do Chuvisco. A subprefeitur...</td>\n",
       "      <td>['Cultura']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>2154</td>\n",
       "      <td>Participe+</td>\n",
       "      <td>Implantação do Parque Arqueológico Cavas de Ou...</td>\n",
       "      <td>['Meio Ambiente']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>Audiência Regional - V Maria V Guilherme</td>\n",
       "      <td>Um boa noite a todos, quero saudar todos os pa...</td>\n",
       "      <td>['Urbanismo e Licenciamento', 'Habitação']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                     canal  \\\n",
       "2061  2802                                Participe+   \n",
       "1419  2154                                Participe+   \n",
       "46      47  Audiência Regional - V Maria V Guilherme   \n",
       "\n",
       "                                                  texto  \\\n",
       "2061  oficinas no Parque do Chuvisco. A subprefeitur...   \n",
       "1419  Implantação do Parque Arqueológico Cavas de Ou...   \n",
       "46    Um boa noite a todos, quero saudar todos os pa...   \n",
       "\n",
       "                                           temas  \n",
       "2061                                 ['Cultura']  \n",
       "1419                           ['Meio Ambiente']  \n",
       "46    ['Urbanismo e Licenciamento', 'Habitação']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpezas simples do texto -- tirar maiusculas etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'texto' : 'texto_original'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_limpo'] = df['texto_original'].str.lower().str.strip('/n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta 37 - iniciativa j - revisar - incluir a implantação de faixa elevada de pedestre ao longo da calçada verde da rua manuel dos reis araújo no jardim marajoara para melhoria da segurança dos munícipes que praticam caminhadas e diversas outras atividades físicas e de lazer no local.\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['texto_limpo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixando as stopwords para limpar os textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/h-pgy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'à', 'ao']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdm_stopwords: list[str] = ['programa de metas',\n",
    "                            'pdm',\n",
    "                            'audiência',\n",
    "                            'audiencia',\n",
    "                            'boa noite',\n",
    "                            'bom dia',\n",
    "                            'boa tarde',\n",
    "                            'meta',\n",
    "                            'olá',\n",
    "                            'iniciativa'\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(pdm_stopwords)\n",
    "\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizando o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/h-pgy/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['texto_limpo'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meta', '37', '-', 'iniciativa', 'j', '-', 'revisar', '-', 'incluir', 'a', 'implantação', 'de', 'faixa', 'elevada', 'de', 'pedestre', 'ao', 'longo', 'da', 'calçada', 'verde', 'da', 'rua', 'manuel', 'dos', 'reis', 'araújo', 'no', 'jardim', 'marajoara', 'para', 'melhoria', 'da', 'segurança', 'dos', 'munícipes', 'que', 'praticam', 'caminhadas', 'e', 'diversas', 'outras', 'atividades', 'físicas', 'e', 'de', 'lazer', 'no', 'local', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens:str, stopwords:set[str]=stopwords)->list[str]:\n",
    "\n",
    "    filtered: list[str]=[token for token in tokens\n",
    "                         if token not in stopwords]\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['37', '-', 'j', '-', 'revisar', '-', 'incluir', 'implantação', 'faixa', 'elevada', 'pedestre', 'longo', 'calçada', 'verde', 'rua', 'manuel', 'reis', 'araújo', 'jardim', 'marajoara', 'melhoria', 'segurança', 'munícipes', 'praticam', 'caminhadas', 'diversas', 'outras', 'atividades', 'físicas', 'lazer', 'local', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover caracteres especiais e pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_char_especiais(tokens:list[str])->list[str]:\n",
    "\n",
    "    #tudo o que não são caracteres alphanumericos\n",
    "    patt = r'[^\\w]'\n",
    "    limpo:list[str] = []\n",
    "    for token in tokens:\n",
    "        token = re.sub(patt, '', token)\n",
    "        if token:\n",
    "            limpo.append(token)\n",
    "    return limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ontem', '123']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remover_char_especiais(['ontem', '123', '@'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens_clean'].apply(remover_char_especiais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['37', 'j', 'revisar', 'incluir', 'implantação', 'faixa', 'elevada', 'pedestre', 'longo', 'calçada', 'verde', 'rua', 'manuel', 'reis', 'araújo', 'jardim', 'marajoara', 'melhoria', 'segurança', 'munícipes', 'praticam', 'caminhadas', 'diversas', 'outras', 'atividades', 'físicas', 'lazer', 'local']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rmover os números - são referência às metas, podem enviesar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'214'.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(tokens:list[str])->list[str]:\n",
    "\n",
    "    cleaned_tokens: list[str] = []\n",
    "\n",
    "    for token in tokens:\n",
    "        while token.startswith('0'):\n",
    "            token=token.lstrip('0')\n",
    "        \n",
    "        if not token.isdigit():\n",
    "            cleaned_tokens.append(token)\n",
    "\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens_clean'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'revisar', 'incluir', 'implantação', 'faixa', 'elevada', 'pedestre', 'longo', 'calçada', 'verde', 'rua', 'manuel', 'reis', 'araújo', 'jardim', 'marajoara', 'melhoria', 'segurança', 'munícipes', 'praticam', 'caminhadas', 'diversas', 'outras', 'atividades', 'físicas', 'lazer', 'local']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remover acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_acentos(tokens:list[str])->list[str]:\n",
    "\n",
    "    return [unidecode(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens_clean'].apply(remover_acentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'revisar', 'incluir', 'implantacao', 'faixa', 'elevada', 'pedestre', 'longo', 'calcada', 'verde', 'rua', 'manuel', 'reis', 'araujo', 'jardim', 'marajoara', 'melhoria', 'seguranca', 'municipes', 'praticam', 'caminhadas', 'diversas', 'outras', 'atividades', 'fisicas', 'lazer', 'local']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/dados_tokenizados.csv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df(df, 'dados_tokenizados.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
