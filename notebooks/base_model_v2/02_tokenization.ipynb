{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DATA_DIR\n",
    "from utils import sample_series, save_df, read_df\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo os dados originais parseados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = read_df('dados_originais_sugestoes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerto</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>Combater as agressões contra crianças e adoles...</td>\n",
       "      <td>Direitos Humanos e Cidadania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.       A meta 3, aqui por Jardim Julieta, de...</td>\n",
       "      <td>Saúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Finalmente a questão alimentação é gravíssima ...</td>\n",
       "      <td>Assistência Social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                excerto  \\\n",
       "3305  Combater as agressões contra crianças e adoles...   \n",
       "103   1.       A meta 3, aqui por Jardim Julieta, de...   \n",
       "353   Finalmente a questão alimentação é gravíssima ...   \n",
       "\n",
       "                         categoria  \n",
       "3305  Direitos Humanos e Cidadania  \n",
       "103                          Saúde  \n",
       "353             Assistência Social  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpezas simples do texto -- tirar maiusculas etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'excerto' : 'texto_original'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_limpo'] = df['texto_original'].str.lower().str.strip('/n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta 37 - iniciativa j - revisar - incluir a implantação de faixa elevada de pedestre ao longo da calçada verde da rua manuel dos reis araújo no jardim marajoara para melhoria da segurança dos munícipes que praticam caminhadas e diversas outras atividades físicas e de lazer no local.\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['texto_limpo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixando as stopwords para limpar os textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/h-pgy/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'à', 'ao']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdm_stopwords: list[str] = ['programa de metas',\n",
    "                            'pdm',\n",
    "                            'audiência',\n",
    "                            'audiencia',\n",
    "                            'boa noite',\n",
    "                            'bom dia',\n",
    "                            'boa tarde',\n",
    "                            'meta',\n",
    "                            'olá',\n",
    "                            'iniciativa'\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(pdm_stopwords)\n",
    "\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizando o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/h-pgy/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['texto_limpo'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['em', 'relação', 'às', 'construções', 'de', 'unidades', ',', 'aqui', 'da', 'região', 'e', 'o', 'ubs', ',', 'nós', 'temos', 'banda', 'coelho', 'e', 'morais', 'na', 'rua', 'sepetiba', 'e', 'tem', 'dinheiro', 'do', 'bid', 'para', 'construção', 'e', 'tem', 'projeto', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens:str, stopwords:set[str]=stopwords)->list[str]:\n",
    "\n",
    "    filtered: list[str]=[token for token in tokens\n",
    "                         if token not in stopwords]\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relação', 'construções', 'unidades', ',', 'aqui', 'região', 'ubs', ',', 'banda', 'coelho', 'morais', 'rua', 'sepetiba', 'dinheiro', 'bid', 'construção', 'projeto', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover caracteres especiais e pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_char_especiais(tokens:list[str])->list[str]:\n",
    "\n",
    "    #tudo o que não são caracteres alphanumericos\n",
    "    patt = r'[^\\w]'\n",
    "    limpo:list[str] = []\n",
    "    for token in tokens:\n",
    "        token = re.sub(patt, '', token)\n",
    "        if token:\n",
    "            limpo.append(token)\n",
    "    return limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ontem', '123']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remover_char_especiais(['ontem', '123', '@'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens_clean'].apply(remover_char_especiais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relação', 'construções', 'unidades', 'aqui', 'região', 'ubs', 'banda', 'coelho', 'morais', 'rua', 'sepetiba', 'dinheiro', 'bid', 'construção', 'projeto']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rmover os números - são referência às metas, podem enviesar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'214'.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(tokens:list[str])->list[str]:\n",
    "\n",
    "    cleaned_tokens: list[str] = []\n",
    "\n",
    "    for token in tokens:\n",
    "        while token.startswith('0'):\n",
    "            token=token.lstrip('0')\n",
    "        \n",
    "        if not token.isdigit():\n",
    "            cleaned_tokens.append(token)\n",
    "\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens_clean'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relação', 'construções', 'unidades', 'aqui', 'região', 'ubs', 'banda', 'coelho', 'morais', 'rua', 'sepetiba', 'dinheiro', 'bid', 'construção', 'projeto']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remover acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_acentos(tokens:list[str])->list[str]:\n",
    "\n",
    "    return [unidecode(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_clean'] = df['tokens_clean'].apply(remover_acentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relacao', 'construcoes', 'unidades', 'aqui', 'regiao', 'ubs', 'banda', 'coelho', 'morais', 'rua', 'sepetiba', 'dinheiro', 'bid', 'construcao', 'projeto']\n"
     ]
    }
   ],
   "source": [
    "print(sample_series(df['tokens_clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/dados_tokenizados.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df(df, 'dados_tokenizados.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
